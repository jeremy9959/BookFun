\contentsline {chapter}{\numberline {1}Linear Regression}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1}Introduction}{1}{section.1.1}%
\contentsline {section}{\numberline {1.2}Least Squares (via Calculus)}{2}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}Exercises}{3}{subsection.1.2.1}%
\contentsline {section}{\numberline {1.3}Least Squares (via Geometry)}{4}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}Exercises}{5}{subsection.1.3.1}%
\contentsline {section}{\numberline {1.4}The Multivariate Case (Calculus)}{6}{section.1.4}%
\contentsline {section}{\numberline {1.5}The Multivariate Case (Geometry)}{9}{section.1.5}%
\contentsline {subsection}{\numberline {1.5.1}Orthogonal Projection}{10}{subsection.1.5.1}%
\contentsline {section}{\numberline {1.6}Centered coordinates}{11}{section.1.6}%
\contentsline {section}{\numberline {1.7}Caveats about Linear Regression}{13}{section.1.7}%
\contentsline {subsection}{\numberline {1.7.1}Basic considerations}{13}{subsection.1.7.1}%
\contentsline {subsection}{\numberline {1.7.2}Simpson's Effect}{14}{subsection.1.7.2}%
\contentsline {subsection}{\numberline {1.7.3}Exercises}{15}{subsection.1.7.3}%
\contentsline {chapter}{\numberline {2}Principal Component Analysis}{16}{chapter.2}%
\contentsline {section}{\numberline {2.1}Introduction}{16}{section.2.1}%
\contentsline {section}{\numberline {2.2}Variance and Covariance}{16}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Variance}{16}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Covariance}{17}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Correlation}{18}{subsection.2.2.3}%
\contentsline {subsection}{\numberline {2.2.4}The covariance matrix}{18}{subsection.2.2.4}%
\contentsline {subsection}{\numberline {2.2.5}Visualizing the covariance matrix}{20}{subsection.2.2.5}%
\contentsline {subsection}{\numberline {2.2.6}Linear Combinations of Features (Scores)}{20}{subsection.2.2.6}%
\contentsline {subsection}{\numberline {2.2.7}Mean and variance of scores}{21}{subsection.2.2.7}%
\contentsline {subsection}{\numberline {2.2.8}Geometry of Scores}{23}{subsection.2.2.8}%
\contentsline {section}{\numberline {2.3}Principal Components}{26}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Change of variance with direction}{26}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}Directions of extremal variance}{27}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}Critical values of the variance}{29}{subsection.2.3.3}%
\contentsline {subsection}{\numberline {2.3.4}Subspaces of extremal variance}{31}{subsection.2.3.4}%
\contentsline {subsection}{\numberline {2.3.5}Definition of Principal Components}{33}{subsection.2.3.5}%
\contentsline {section}{\numberline {2.4}Dimensionality Reduction via Principal Components}{34}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Loadings}{38}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}The singular value decomposition}{39}{subsection.2.4.2}%
\contentsline {section}{\numberline {2.5}Eigenvalues and Eigenvectors of Real Symmetric Matrices (The Spectral Theorem)}{40}{section.2.5}%
\contentsline {subsection}{\numberline {2.5.1}Gram-Schmidt}{40}{subsection.2.5.1}%
\contentsline {subsection}{\numberline {2.5.2}The spectral theorem}{41}{subsection.2.5.2}%
\contentsline {chapter}{\numberline {3}Probability and Bayes Theorem}{45}{chapter.3}%
\contentsline {section}{\numberline {3.1}Introduction}{45}{section.3.1}%
\contentsline {section}{\numberline {3.2}Probability Basics}{45}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Discrete probability examples}{46}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Continuous probability examples}{47}{subsection.3.2.2}%
\contentsline {section}{\numberline {3.3}Conditional Probability and Bayes Theorem}{48}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Bayes Theorem}{48}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}An example}{49}{subsection.3.3.2}%
\contentsline {section}{\numberline {3.4}Independence}{50}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Examples}{51}{subsection.3.4.1}%
\contentsline {subsubsection}{\numberline {3.4.1.1}Coin Flipping}{51}{subsubsection.3.4.1.1}%
\contentsline {subsubsection}{\numberline {3.4.1.2}A simple `mixture'}{51}{subsubsection.3.4.1.2}%
\contentsline {subsubsection}{\numberline {3.4.1.3}An example with a continuous distribution}{52}{subsubsection.3.4.1.3}%
\contentsline {section}{\numberline {3.5}Random Variables, Mean, and Variance}{53}{section.3.5}%
\contentsline {subsection}{\numberline {3.5.1}Independence and Random Variables}{56}{subsection.3.5.1}%
\contentsline {subsection}{\numberline {3.5.2}Expectation, Mean and Variance}{56}{subsection.3.5.2}%
\contentsline {subsubsection}{\numberline {3.5.2.1}Variance}{58}{subsubsection.3.5.2.1}%
\contentsline {section}{\numberline {3.6}Models and Likelihood}{59}{section.3.6}%
\contentsline {subsection}{\numberline {3.6.1}Maximum Likelihood (Discrete Case)}{59}{subsection.3.6.1}%
\contentsline {subsection}{\numberline {3.6.2}Maximum Likelihood (Continuous Case)}{60}{subsection.3.6.2}%
\contentsline {subsection}{\numberline {3.6.3}Linear Regression and likelihood}{61}{subsection.3.6.3}%
\contentsline {section}{\numberline {3.7}Bayesian Inference}{61}{section.3.7}%
\contentsline {subsection}{\numberline {3.7.1}Bayesian experiments with the normal distribution}{63}{subsection.3.7.1}%
\contentsline {subsection}{\numberline {3.7.2}Bayesian coin flipping}{66}{subsection.3.7.2}%
\contentsline {chapter}{\numberline {4}The Naive Bayes classification method}{69}{chapter.4}%
\contentsline {section}{\numberline {4.1}Introduction}{69}{section.4.1}%
\contentsline {section}{\numberline {4.2}An example dataset}{70}{section.4.2}%
\contentsline {section}{\numberline {4.3}Bernoulli tests}{70}{section.4.3}%
\contentsline {section}{\numberline {4.4}Feature vectors}{73}{section.4.4}%
\contentsline {section}{\numberline {4.5}Likelihood}{74}{section.4.5}%
\contentsline {section}{\numberline {4.6}The Bag of Words}{75}{section.4.6}%
\contentsline {section}{\numberline {4.7}Other applications}{77}{section.4.7}%
\contentsline {chapter}{\numberline {5}Support Vector Machines}{78}{chapter.5}%
\contentsline {section}{\numberline {5.1}Introduction}{78}{section.5.1}%
\contentsline {section}{\numberline {5.2}A simple example}{78}{section.5.2}%
\contentsline {section}{\numberline {5.3}The general case}{80}{section.5.3}%
\contentsline {subsection}{\numberline {5.3.1}Hyperplanes}{81}{subsection.5.3.1}%
\contentsline {subsection}{\numberline {5.3.2}Linear separability and Margins}{81}{subsection.5.3.2}%
\contentsline {section}{\numberline {5.4}Convexity, Convex Hulls, and Margins}{85}{section.5.4}%
\contentsline {section}{\numberline {5.5}Finding the Optimal Margin Classifier}{92}{section.5.5}%
\contentsline {subsection}{\numberline {5.5.1}Relaxing the constraints}{94}{subsection.5.5.1}%
\contentsline {subsection}{\numberline {5.5.2}Sequential Minimal Optimization}{95}{subsection.5.5.2}%
\contentsline {section}{\numberline {5.6}Inseparable Sets}{99}{section.5.6}%
\contentsline {subsection}{\numberline {5.6.1}Best Separating Hyperplanes}{99}{subsection.5.6.1}%
\contentsline {subsection}{\numberline {5.6.2}Nonlinear kernels}{99}{subsection.5.6.2}%
\contentsline {section}{\numberline {5.7}Exercises}{99}{section.5.7}%
\contentsline {chapter}{References}{101}{chapter*.40}%
